{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# easier access to tensorflow distributions\n",
    "ds = tf.contrib.distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advanced inference tool should support some tweaking and instrospection by the user, therefore a composable design in important. An ideal interface would have high level constructs for the model and the parameters and utilities to compute the most relevant statistical quantities. Further down the line, serialization would be important to share/import/export statistical models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About statistical models, we can clearly distinguish three different types:\n",
    "1. Those for which we can analytically evaluate the normalized pdf (e.g. multibin Poisson likelihood, gaussian, bijectable-tranform over a distribribution with and analytical pdf)\n",
    "2. Those for which we can compute the unnormalized pdf but we do not analytically know the normalization.\n",
    "3. Those for which we cannot compute even the unnormalized pdf, because they are complex and/or probabilistc/stochastic.\n",
    "\n",
    "In HEP, we normally deal with the first type (a realistic statiscal model for each event is of the third type but we cannot deal with that so we use sample summary statistics or very simplified pdf modelling, all of it corresponding to type 1).\n",
    "\n",
    "I could not think of an example usage of type 2 statistical models in HEP, but in principle are equivalent to type 1 as long as you compute the normalization integral.\n",
    "\n",
    "Therefore, the initial focus of the tools should be type 1 statistical models. Other tools like Edward/Pyro deal already with probabilistic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(2)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.Poisson([2.,2.]).batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poisson_ind = ds.Independent(distribution=ds.Poisson([3.,4.]),\n",
    "                            reinterpreted_batch_ndims=1)\n",
    "poisson_ind.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 6.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(poisson_ind.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.109628 , -4.5150933, -4.109628 ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(poisson_ind.log_prob([[2.,1.],[1.,1.], [2.,1.]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
